{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "eU3_shT9J-M6"
      },
      "outputs": [],
      "source": [
        "# fisrt install these packages : python-telegram-bot==13.7 telethon utils requests config\n",
        "\n",
        "from telegram import Update , ReplyKeyboardMarkup\n",
        "from telegram.ext import Updater, CommandHandler, CallbackContext,ConversationHandler, MessageHandler, Filters\n",
        "from telegram.error import TelegramError\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatSession:\n",
        "    def __init__(self, api_key, model):\n",
        "        self.api_key = api_key\n",
        "        self.model = model\n",
        "        self.headers = {\n",
        "            \"Authorization\": f\"Bearer {api_key}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "        self.history = [\n",
        "            {\"role\": \"system\", \"content\": \"Answer as concisely as possible, make sure your answer does not exceed 4000 characters, and respond in the language in which the question is asked.\"}\n",
        "        ]\n",
        "\n",
        "    def chat_request(self, prompt):\n",
        "        self.history.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "        data = {\n",
        "            \"model\": self.model,\n",
        "            \"messages\": self.history,\n",
        "            \"stream\": False\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.post(\n",
        "                \"https://openrouter.ai/api/v1/chat/completions\",\n",
        "                headers=self.headers,\n",
        "                json=data\n",
        "            )\n",
        "            if response.status_code == 200:\n",
        "                response_json = response.json()\n",
        "                if \"choices\" in response_json:\n",
        "                    model_response = response_json[\"choices\"][0][\"message\"][\"content\"]\n",
        "                    self.history.append({\"role\": \"assistant\", \"content\": model_response})\n",
        "                    return model_response\n",
        "                else:\n",
        "                    print(\"Response hasn't 'choices' field.\")\n",
        "            else:\n",
        "                print(f\"API Error: {response.status_code} - {response.text}\")\n",
        "        except requests.RequestException as e:\n",
        "            print(f\"Request Error: {e}\")\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "qvkhBGqifLcz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "p43Sz3IAaR7i"
      },
      "outputs": [],
      "source": [
        "TOKEN = \"\"   # Telgram bot Token\n",
        "\n",
        "API_KEY_deepseek , MODEL_deepseek = \"\" , \"\" # You can take any LLM API from openrouter.ai. Here, I chose Deepseek and Gemini models\n",
        "API_KEY_gemini , Model_gemini= \"\" , \"\"\n",
        "\n",
        "\n",
        "API , Model = [API_KEY_deepseek , API_KEY_gemini] ,[MODEL_deepseek , Model_gemini]\n",
        "\n",
        "chat_list , chat_number= {} , \"\"\n",
        "\n",
        "def start(update , context):\n",
        "  update.message.reply_text(\"What? press /chat_session or Fuck yourself\")\n",
        "\n",
        "\n",
        "def chat_history(update , context):\n",
        "  markup = ReplyKeyboardMarkup([[\"/chat_new\"]+[f\"/chat_{i+1}\" for i in range(len(chat_list))]],\n",
        "\n",
        "                               one_time_keyboard = True)\n",
        "  update.message.reply_text(\"Choose your chat:\",\n",
        "                            reply_markup=markup)\n",
        "\n",
        "\n",
        "def chat_index(update , context):\n",
        "  global chat_number\n",
        "  if update.message.text == \"/chat_new\":\n",
        "    update.message.reply_text(\"starting new chat...\" )\n",
        "\n",
        "    reply_keyboard = [[\"ChatGPT\", \"DeepSeek\"]]\n",
        "    markup = ReplyKeyboardMarkup(reply_keyboard,\n",
        "                                 one_time_keyboard = True)\n",
        "    update.message.reply_text(\"Choose a Model:\",\n",
        "                              reply_markup=markup)\n",
        "    i = len(chat_list)\n",
        "    chat_number = f\"chat_{i+1}\"\n",
        "  else:\n",
        "    chat_number = update.message.text.replace(\"/\", \"\")\n",
        "    update.message.reply_text(f\"You're in {chat_number}\" )\n",
        "\n",
        "\n",
        "def handle_message(update , context):\n",
        "  global chat_list\n",
        "  global API\n",
        "  global Model\n",
        "  global chat_number\n",
        "  choice = update.message.text\n",
        "\n",
        "  if choice == \"ChatGPT\":\n",
        "      update.message.reply_text(\"I was cheating, the model is Gemini :) ask your dumb question\")\n",
        "      API_KEY_gemini , Model_gemini = API[1] , Model[1]\n",
        "      chat_list[chat_number] = ChatSession(api_key = API_KEY_gemini ,\n",
        "                                           model = Model_gemini )\n",
        "\n",
        "  elif choice == \"DeepSeek\":\n",
        "      update.message.reply_text(\"You're supporting chinese communism...ask your dumb question\")\n",
        "      API_KEY_deepseek , MODEL_deepseek = API[0] , Model[0]\n",
        "      chat_list[chat_number] =  ChatSession(api_key = API_KEY_deepseek ,\n",
        "                                           model = MODEL_deepseek )\n",
        "\n",
        "  else:\n",
        "      prompt = choice\n",
        "      thinking_massage = update.message.reply_text(\"Thinking...\")\n",
        "      respond = chat_list[chat_number].chat_request(prompt)\n",
        "      thinking_massage.edit_text(respond)\n",
        "\n",
        "updater = Updater(TOKEN, use_context=True)\n",
        "dispatch = updater.dispatcher\n",
        "\n",
        "dispatch.add_handler(CommandHandler(\"start\" , start))\n",
        "\n",
        "dispatch.add_handler(CommandHandler(\"chat_session\" , chat_history))\n",
        "\n",
        "dispatch.add_handler(CommandHandler(\"chat_new\", chat_index))\n",
        "\n",
        "for i in range(100):  # Maximum number of Chat sessions\n",
        "  dispatch.add_handler(CommandHandler(f\"chat_{i+1}\", chat_index))\n",
        "\n",
        "dispatch.add_handler(MessageHandler(Filters.text , handle_message))\n",
        "\n",
        "updater.start_polling()\n",
        "updater.idle()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}